{ 
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-S9EwVjCGwX"
   },
   "source": [
    "# Deep Learning for Computer Vision with TensorFlow 2.0\n",
    "\n",
    "Table of contents:\n",
    "[Lab 0](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/00_test_install.ipynb) | \n",
    "[Lab 1](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/01_linear_regression.ipynb) | \n",
    "[Lab 2](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/02_tensorflow_logistic_regression.ipynb) | \n",
    "[Lab 3a](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/03a_tensorflow_deep_network.ipynb) | \n",
    "[Lab 3b](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/03b_deep_mnist_visualize.ipynb) | \n",
    "[Lab 4](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/04_mnist_cnn.ipynb) | \n",
    "[Lab 5](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/05_data_prep.ipynb) | \n",
    "[Lab 6](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/06_transfer_learning.ipynb) | \n",
    "\n",
    "# Lab 5: Data Prep\n",
    "\n",
    "If you ever want to start over just go to the menu at the top and select Runtime ->  Restart runtime.  (Please do not use Runtime -> Reset all runtimes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOhB_5YVirXW"
   },
   "source": [
    "In this notebook we will delve further into dataset creation. The MNIST dataset used previously was extremly simple and this notebook will give you a better idea of how this is done for typical applications. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5YWNi68irXW"
   },
   "outputs": [],
   "source": [
    "# Cell 5.1\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "if tf.__version__ != \"2.0.0\":\n",
    "    !pip install tensorflow-gpu==2.0.0\n",
    "    print(\"Please go to Runtime -> restart runtime and then, once that finishes, rerun this cell.\")\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "print(\"TensorFlow version is \", tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.transforms as trans\n",
    "\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtExOylGirXZ"
   },
   "source": [
    "The next cell will download a cat and dog dataset so that the contents can be examined in more detail. The idea is to show how this process is typically completed.\n",
    "\n",
    "The `base_dir` variable is set to the top of the directories to be examined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uOvVfxfzirXa"
   },
   "outputs": [],
   "source": [
    "# Cell 5.2\n",
    "\n",
    "zip_file = tf.keras.utils.get_file(origin=\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\", \n",
    "                                   cache_dir='.',fname=\"cats_and_dogs_filtered.zip\", extract=True)\n",
    "\n",
    "base_dir, _ = os.path.splitext(zip_file)\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ybj1_3dirXc"
   },
   "source": [
    "Show the directory structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDUykgXairXc"
   },
   "outputs": [],
   "source": [
    "# Cell 5.3\n",
    "\n",
    "# code to show directory structure\n",
    "print(os.listdir('./datasets'))\n",
    "\n",
    "print(os.listdir('./datasets/cats_and_dogs_filtered'))\n",
    "\n",
    "print(os.listdir('./datasets/cats_and_dogs_filtered/train'))\n",
    "\n",
    "dog_list = os.listdir('./datasets/cats_and_dogs_filtered/train/dogs')\n",
    "print (dog_list[0:5])\n",
    "print (len(dog_list))\n",
    "\n",
    "cat_list = os.listdir('./datasets/cats_and_dogs_filtered/train/cats')\n",
    "print (cat_list[0:5])\n",
    "print (len(cat_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F8a4hhSkirXe"
   },
   "source": [
    "Explore table of cat pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJR5uubdirXe"
   },
   "outputs": [],
   "source": [
    "# Cell 5.4\n",
    "\n",
    "# code to show table of pics from cats\n",
    "\n",
    "# update offset by values of 9 to see the next set of pictures\n",
    "offset = 9\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    img_file = plt.imread('./datasets/cats_and_dogs_filtered/train/cats/' + cat_list[i+ offset])\n",
    "    #img_file = plt.resize()\n",
    "    plt.imshow(img_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8OpL1wiirXg"
   },
   "source": [
    "Explore table of dog pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbmGif25irXh"
   },
   "outputs": [],
   "source": [
    "# Cell 5.5\n",
    "\n",
    "# code to show table of pics from dogs\n",
    "\n",
    "# update offset by values of 9 to see the next set of pictures\n",
    "offset = 9\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    img_file = plt.imread('./datasets/cats_and_dogs_filtered/train/dogs/' + dog_list[i+offset])\n",
    "    #img_file = plt.resize()\n",
    "    plt.imshow(img_file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IeNx4ugxirXl"
   },
   "source": [
    "The next cell shows how the training and validation directories are setup for the training process. These paths are used to create the datasets that will be used during training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OeeaCSzYirXl"
   },
   "outputs": [],
   "source": [
    "# Cell 5.6\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "print ('Total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "print ('Total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "print ('Total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "print ('Total validation dog images:', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqjjKTyFirXo"
   },
   "source": [
    "Show function call for the Image Data Generator class and some common arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0giOm8LirXp"
   },
   "outputs": [],
   "source": [
    "# Cell 5.7\n",
    "\n",
    "gen =keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255)\n",
    "\n",
    "gimg = plt.imread('./datasets/cats_and_dogs_filtered/train/cats/cat.952.jpg')\n",
    "ximg = np.expand_dims(gimg,0)\n",
    "\n",
    "img_iter = gen.flow(ximg)\n",
    "\n",
    "#aug_imgs=[next(img_iter)[0].astype(np.uint8) for i in range(9)]\n",
    "aug_imgs=[next(img_iter)[0] for i in range(9)]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    img_file = aug_imgs[i]\n",
    "    plt.imshow(img_file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c143kLEnirXr"
   },
   "source": [
    "Using the directories provided above two ImageDataGenerators can be created, one for training, the other for validation. These generators will apply augmentations to the images as they are pulled from the training and validation directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2INI9s6irXr"
   },
   "outputs": [],
   "source": [
    "# Cell 5.8\n",
    "\n",
    "image_size = 160 # All images will be resized to 160x160\n",
    "batch_size = 9\n",
    "\n",
    "# Rescale all images by 1./255 and apply image augmentation\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "                rescale=1./255)\n",
    "\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_dir,  # Source directory for the training images\n",
    "                target_size=(image_size, image_size),  \n",
    "                batch_size=batch_size,\n",
    "                # Since we use binary_crossentropy loss, we need binary labels\n",
    "                class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                validation_dir, # Source directory for the validation images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='binary')\n",
    "\n",
    "t_imgs = iter(train_generator)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    img_file = t_imgs[0][0][i]\n",
    "    plt.imshow(img_file)\n",
    "plt.show()\n",
    "\n",
    "print ('Now the validation images')\n",
    "print ('')\n",
    "print ('')\n",
    "\n",
    "\n",
    "\n",
    "v_imgs = iter(validation_generator)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    img_file = v_imgs[0][0][i]\n",
    "    plt.imshow(img_file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Quh0cCuEirXt"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7Jc9tZdirXu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "05_data_prep.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
