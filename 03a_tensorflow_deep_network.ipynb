{  
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03a_tensorflow_deep_network.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.10"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-S9EwVjCGwX",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning for Computer Vision with TensorFlow 2.0\n",
        "\n",
        "Table of contents:\n",
        "[Lab 0](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/00_test_install.ipynb) | \n",
        "[Lab 1](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/01_linear_regression.ipynb) | \n",
        "[Lab 2](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/02_tensorflow_logistic_regression.ipynb) | \n",
        "[Lab 3a](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/03a_tensorflow_deep_network.ipynb) | \n",
        "[Lab 3b](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/03b_deep_mnist_visualize.ipynb) | \n",
        "[Lab 4](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/04_mnist_cnn.ipynb) | \n",
        "[Lab 5](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/05_data_prep.ipynb) | \n",
        "[Lab 6](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/06_transfer_learning.ipynb) | \n",
        "\n",
        "# Lab 3: Deep MNIST\n",
        "\n",
        "If you ever want to start over just go to the menu at the top and select Runtime ->  Restart runtime.  (Please do not use Runtime -> Reset all runtimes.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvaNoa6igi_Q",
        "colab_type": "text"
      },
      "source": [
        "In this exercise you will again apply what you've learned in the lecture. This is another model for an MNIST classifier but this model will use a deep network instead of a shallow one as in the last example. \n",
        "\n",
        "Run each of the cells to create the classifier model, train the model, and test the model to see how well the model performs. \n",
        "\n",
        "You can modify parameters in certain cells to change the way that the training is performed and see what happens. Experiment to see if you can get better results than the defaults. \n",
        "\n",
        "This cell imports tensorflow as well as Keras which will be used for the layer description."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J20xTt_Bgi_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.1\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "if tf.__version__ != \"2.0.0\":\n",
        "    !pip install tensorflow-gpu==2.0.0\n",
        "    print(\"Please go to Runtime -> restart runtime and then, once that finishes, rerun this cell.\")\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "%pylab inline\n",
        "\n",
        "print ('cell finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yluZqG_gi_T",
        "colab_type": "text"
      },
      "source": [
        "Notice that the dataset loading and modification code is exactly the same as in the shallow model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICz8RUpsgi_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.2\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# Numpy defaults to dtype=float64; TF defaults to float32. Stick with float32.\n",
        "x_train, x_test = x_train / np.float32(255), x_test / np.float32(255)\n",
        "y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n",
        "\n",
        "\n",
        "print ('cell finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYiHOctGgi_V",
        "colab_type": "text"
      },
      "source": [
        "The dataset conversion code is also exactly the same.\n",
        "\n",
        "Variables x_train, y_train, etc. are tensors that can be converted into a Dataset with the statements shown below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idDgToPVgi_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.3\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat()\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "\n",
        "print ('cell finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KveZEOYmgi_Y",
        "colab_type": "text"
      },
      "source": [
        "The next cell contains a number of constants used in the model and training. Putting these variables in one location allows for easy modification throughout the model. Notice that a new variable HIDDEN_SIZE has been added. This will control the size of the hidden layer that is added for the deep network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7pcEKxYgi_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.4\n",
        "\n",
        "BATCH_SIZE=100\n",
        "\n",
        "HIDDEN_SIZE = 300\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "IMG_HT = 28\n",
        "IMG_W = 28\n",
        "\n",
        "print ('cell finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss441jrJgi_a",
        "colab_type": "text"
      },
      "source": [
        "The next two statements are used to specify the batch sizes for the training and testing datasets. Additionally the training dataset is shuffled so that successive runs will use a different training image order. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WDaiD-fgi_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.5\n",
        "\n",
        "train_ds = train_ds.shuffle(60000).batch(BATCH_SIZE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE)\n",
        "\n",
        "print ('cell finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEwhYHZqgi_c",
        "colab_type": "text"
      },
      "source": [
        "This cell is again the same as in the last example. \n",
        "\n",
        "This cell is meant to help understand the details of the MNIST dataset. You will notice a number of print statements that will print out different aspects of MNIST. Uncomment these and run the cell to see the results. \n",
        "\n",
        "The first print statement (2 lines) will print out the sizes of the train and test sets. \n",
        "\n",
        "The second shows how the labels are formatted. You can change the index used to pick a particular image to see different labels. \n",
        "\n",
        "The next print statement shows the shape of the fields of training data set\n",
        "\n",
        "The next statements show the length of a row of image data, and the contents of one row in the middle\n",
        "\n",
        "The final two statements plot the image from the index. Again feel free to modify the indices to see different images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEuvdhbfgi_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.6\n",
        "\n",
        "# Run this cell to understand the format of the dataset. Uncomment the print commands one by one to understand what\n",
        "# the data set looks like. As you uncomment a line use shift-enter to run the cell once more. In the first print you\n",
        "# actually have to uncomment two lines or you will get an error. \n",
        "\n",
        "img_index = 7\n",
        "\n",
        "# 1. There are 55k, 5k, and 10k examples in train, validation, and test.\n",
        "print ('Train, test: %d, %d' % \n",
        "      (len(x_train), len(x_test)))\n",
        "\n",
        "# 2. The label is an integer\n",
        "print ('label = {}'.format(y_train[4]))\n",
        "\n",
        "# 3. The shapes of the two different data types in the Dataset is shown here\n",
        "print ('x shape = {}'.format(np.shape(x_train)))\n",
        "print ('y_shape = {}'.format(np.shape(y_train)))\n",
        "\n",
        "# 4. An image is a 28 by 288 array of  pixels.\n",
        "print ('length of first row = {}'.format(len(x_train[4])))\n",
        "print (x_train[img_index][10]) # This prints the 11th row of 28. The nonzero values represent the pixel values through\n",
        "                       # the middle of the digit\n",
        "\n",
        "# 5. To display an image\n",
        "pylab.imshow(x_train[img_index], cmap=pylab.cm.gray_r)   \n",
        "pylab.title('Label: %d' % y_train[4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "xP99prBAgi_e",
        "colab_type": "text"
      },
      "source": [
        "The next cell contains a function that describes the classification network. A Keras Sequential model is used to describe a single classification layer. The classification layer is a dense layer so it will input all of the pixels of an image at a time. Since the MNIST data is an array of 28 x 28 a Flatten layer is needed to convert it into a flat array of 784 pixels. Notice that the Flatten layer uses the IMG_HT and IMG_W constants to determine how to flatten the image. \n",
        "\n",
        "This model now contains an extra hidden layer that will be used to add non-linearity for more complex model behavior. The size of the hidden layer is specified by the new constant HIDDEN_SIZE that was added earlier. \n",
        "\n",
        "The dense layer is then 784 pixels as input and NUM_CLASSES(10) output. One class for each of our 10 digit types. \n",
        "\n",
        "The activation is specified as softmax so that probabilities are used for neuron output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JuP2HlPgi_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.7\n",
        "\n",
        "def model():\n",
        "    model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=[IMG_HT,IMG_W]),\n",
        "    layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "  ])\n",
        "    return model\n",
        "\n",
        "print ('cell finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHfQAA0sgi_g",
        "colab_type": "text"
      },
      "source": [
        "Just as in the previous notebook the model function will be called to create the Keras model for the classification. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI4c-khcgi_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.8\n",
        "\n",
        "mnist_model = model()\n",
        "\n",
        "mnist_model.summary()\n",
        "\n",
        "print ('cell finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0byQ2XQgi_j",
        "colab_type": "text"
      },
      "source": [
        "Also as previously discussed the model needs to be compiled for use.  \n",
        "\n",
        "Notice that this code does not change for a deep network, it is exactly the same except that we decided to use the adam optimizer. \n",
        "\n",
        "The metrics that will be displayed are the classification accuracy, though feel free to add others. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6la4rSbgi_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.9\n",
        "\n",
        "mnist_model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print ('cell finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRUyJNQJgi_l",
        "colab_type": "text"
      },
      "source": [
        "Let's try the model out before it is trained to see how well it does. Since the weights and biases are random values there is a chance (about 1 in 10) that the correct value is returned from classification. This code will allow you to try an example to see if it works. \n",
        "\n",
        "The `image_index` variable is used to grab an example from the training dataset. The expected label is captured in variable `exp_label`. The pixel data is captured in `img`. These values are fed to the network and the predict function called to generate the output in variable `label`. \n",
        "\n",
        "The results are printed out and the image plotted so you can see which one it is. \n",
        "\n",
        "Experiment with the `image_index` variable to see if you can find images where the untrained model correctly predicts the label. You will need to change the index and rerun this cell. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKvmfYCvgi_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.10\n",
        "\n",
        "image_index = 109\n",
        "exp_label = y_train[image_index]\n",
        "\n",
        "img = (np.expand_dims(x_train[image_index],0))\n",
        "\n",
        "label = mnist_model.predict(img)\n",
        "\n",
        "print (\"calculated label = {} expected label = {}\".format(np.argmax(label), exp_label))\n",
        "pylab.imshow(x_train[image_index], cmap=pylab.cm.gray_r)   \n",
        "pylab.title('Label: %d' % y_train[image_index]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEg5QKslgi_n",
        "colab_type": "text"
      },
      "source": [
        "With a deep network you will notice that the training takes more time. This is especially noticeable on a CPU vs a GPU. \n",
        "\n",
        "The training dataset train_ds is input to the fit method and the training is run using the number of epochs specified. The steps_per_epoch is usually specified as the length of the dataset divided by the batch size so that the there are enough steps in each epoch to run all of the examples. \n",
        "\n",
        "The training process will use the batch size that was applied to the dataset earlier. \n",
        "\n",
        "This time you might also notice some lines with perfect accuracy. That is not for the complete training set but only a single batch.\n",
        "\n",
        "The `verbose` keyword specifies how much data is output for each epoch. A setting of 2 will output a single line per epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhO4ZpHQgi_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.11\n",
        "\n",
        "history = mnist_model.fit(\n",
        "  train_ds,\n",
        "  epochs=50, steps_per_epoch=600,verbose=2)\n",
        "\n",
        "\n",
        "print ('cell finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjcXYgDvgi_p",
        "colab_type": "text"
      },
      "source": [
        "During the training the accuracy and loss are displayed for each epoch. When the accuracy plateaus there is no need to run further epochs. \n",
        "\n",
        "This is the training accuracy. It is not the same as the testing accuracy. As mentioned in the lecture the data has been split into a training set and a testing set. The test data was never seen by the model during training but is used to test how well the model generalizes. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAGWfLYdgi_r",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The previous cell showed the training accuracy because it used the training images. To get the testing accuracy let's run the accuracy on the test images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOJBHYuagi_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 3a.12 \n",
        "\n",
        "mnist_model.evaluate(\n",
        "    test_ds, steps=32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q81-1oYCgi_t",
        "colab_type": "text"
      },
      "source": [
        "The testing accuracy should be much improved over the shallow model because the deep model is better able to handle the complexities in the data. \n",
        "\n",
        "The testing accuracy is slightly different, but remember the model was not trained on those images, the model has never seen those images before, so having a similar accuracy is a good sign. \n",
        "\n",
        "The accuracy displayed on the first line is for the last epoch of the testing data. The final accuracy is displayed on the last line. \n",
        "\n",
        "You might think that over 90% accuracy is good, but the accuracy of this model has great room for improvement. Going forward more accurate models will be developed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "C2jWPTe0gi_t",
        "colab_type": "text"
      },
      "source": [
        "Go back to cell 10 and change the image_index once more. The model now uses the trained weight values. Nine out of ten times as we see by the accuracy it should pick the correct label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx0HBEGJgi_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
