{  
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-S9EwVjCGwX"
   },
   "source": [
    "# Deep Learning for Computer Vision with TensorFlow 2.0\n",
    "\n",
    "Table of contents:\n",
    "[Lab 0](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/00_test_install.ipynb) | \n",
    "[Lab 1](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/01_linear_regression.ipynb) | \n",
    "[Lab 2](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/02_tensorflow_logistic_regression.ipynb) | \n",
    "[Lab 3a](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/03a_tensorflow_deep_network.ipynb) | \n",
    "[Lab 3b](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/03b_deep_mnist_visualize.ipynb) | \n",
    "[Lab 4](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/04_mnist_cnn.ipynb) | \n",
    "[Lab 5](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/05_data_prep.ipynb) | \n",
    "[Lab 6](https://colab.research.google.com/github/embedded-vision/dlcvtf2/blob/master/06_transfer_learning.ipynb) | \n",
    "\n",
    "# Lab 4: MNIST CNN\n",
    "\n",
    "If you ever want to start over just go to the menu at the top and select Runtime ->  Restart runtime.  (Please do not use Runtime -> Reset all runtimes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRvcL9Rah7sL"
   },
   "source": [
    "As we saw in the lecture fully connected models are impractical for larger images. We need a better way to classify larger images and CNN models can help significantly. \n",
    "\n",
    "TensorFlow with Keras makes describing even complex CNN models easy. The other beauty of this framework is that the only part that will change is the model layer description. Virtually the rest of the model remains the same as used previously. \n",
    "\n",
    "This model takes much more computation to run on the CPU so this is where the GPU is necessary.  Notice that there is also a TPU option but this model is not setup to optimally use the TPU so don't use that right now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWFEEzLGh7sM"
   },
   "outputs": [],
   "source": [
    "# Cell 4.1\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "if tf.__version__ != \"2.0.0\":\n",
    "    !pip install tensorflow-gpu==2.0.0\n",
    "    print(\"Please go to Runtime -> restart runtime and then, once that finishes, rerun this cell.\")\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "\n",
    "print ('cell finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lp8FUvyLh7sO"
   },
   "source": [
    "The first cell reads the data sets as we have been doing all along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vf_yo4-Ah7sP"
   },
   "outputs": [],
   "source": [
    "# Cell 4.2\n",
    "\n",
    "BATCH_SIZE=100\n",
    "\n",
    "HIDDEN_SIZE = 1024\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "IMG_HT = 28\n",
    "IMG_W = 28\n",
    "\n",
    "print ('cell finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-oBxjmwVh7sS"
   },
   "source": [
    "Now we define the input variable to accept digit input pixel values, and the expected result from the model. These look very familiar as we have used the same in previous models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwBpB5j0h7sS"
   },
   "outputs": [],
   "source": [
    "# Cell 4.3\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Numpy defaults to dtype=float64; TF defaults to float32. Stick with float32.\n",
    "x_train, x_test = x_train / np.float32(255), x_test / np.float32(255)\n",
    "y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat()\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# DON'T CHANGE THESE VARIABLES OR YOU WILL BREAK THINGS\n",
    "NUM_PIXELS = 28 * 28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "print ('cell finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oy2Ztpp2h7sU"
   },
   "outputs": [],
   "source": [
    "# Cell 4.4\n",
    "\n",
    "train_ds = train_ds.shuffle(60000).batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "\n",
    "print ('cell finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDKwvbUyh7sW"
   },
   "source": [
    "This cell shows how to describe the CNN model using TensorFlow and Keras. The model function contains a sequential model that describes all of the layers of our network. \n",
    "\n",
    "This function accepts a single input 2D image and each of the layers passes the output tensor to the next layer.  \n",
    "\n",
    "The first convolutional layer accepts the input image and generates an output tensor which is the input to the next layer. The next layer generates a new output applied to the next layer. This occurs successively until all of the layers have been defined.  \n",
    "\n",
    "Notice that each layer has a number of parameters that allow specification of the activation type, number of filters, kernel size, etc. There are a lot more parameters that are defaulted but can be specified if needed to get better results. \n",
    "\n",
    "The Dropout layer is used when the model is fit to the data, but will not be used during evaluation or prediction. This behavior is built in to Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OgNNUkvUh7sX"
   },
   "outputs": [],
   "source": [
    "# Cell 4.5\n",
    "\n",
    "def model():\n",
    "    model = keras.Sequential([\n",
    "    layers.Reshape(\n",
    "        target_shape=[28, 28, 1],\n",
    "        input_shape=(28, 28,)),\n",
    "  \n",
    "    layers.Conv2D(filters=32,kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "    layers.Conv2D(filters=64,kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "    layers.Dropout(rate=0.4),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "  ])\n",
    "    return model\n",
    "\n",
    "print ('cell finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SphimLph7sY"
   },
   "source": [
    "Just as in previous networks the model function will create the model. Notice the summary shows a much bigger model than any used previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "It-9txwLh7sZ"
   },
   "outputs": [],
   "source": [
    "# Cell 4.6\n",
    "\n",
    "conv_model = model() # calls the layer function\n",
    "\n",
    "conv_model.summary()\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6kyyGAlh7sb"
   },
   "source": [
    "Notice the the compilation parameters are exactly as used before, even though the model is much larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bw963Ffyh7sb"
   },
   "outputs": [],
   "source": [
    "# Cell 4.7\n",
    "\n",
    "conv_model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print ('cell finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0sbjw8mwh7se"
   },
   "source": [
    "The next cell will train or fit the model. It will use the training dataset train_ds, run 50 times or 50 epochs through the data, with 600 minibatches per epoch. If you take the steps_per_epoch * the mini-batch size, it should be greater than or equal to the size of the training set. \n",
    "\n",
    "Since this is a much larger model than previously used, it will take much longer to train on a CPU. A GPU is needed for reasonable performance in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQgTVWGxh7se"
   },
   "outputs": [],
   "source": [
    "# Cell 4.8\n",
    "\n",
    "history = conv_model.fit(\n",
    "  train_ds,\n",
    "  epochs=50,  \n",
    "  steps_per_epoch=600,verbose=2)\n",
    "\n",
    "\n",
    "print ('cell finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8RYJ0H2h7sg"
   },
   "source": [
    "As in previous models the accuracy of the model is plot as before. The accuracy should be better, even though this is a tiny dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8KUIZyAh7sh"
   },
   "outputs": [],
   "source": [
    "# Cell 4.9\n",
    "\n",
    "pylab.plot(history.history['accuracy'],'b')\n",
    "pylab.title('Model accuracy')\n",
    "pylab.ylabel('Accuracy')\n",
    "pylab.xlabel('Epoch')\n",
    "pylab.legend(['Train'], loc='upper left')\n",
    "pylab.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "pylab.plot(history.history['loss'], 'r')\n",
    "#plt.plot(history.history['val_loss'])\n",
    "pylab.title('Model loss')\n",
    "pylab.ylabel('Loss')\n",
    "pylab.xlabel('Epoch')\n",
    "pylab.legend(['Train'], loc='upper left')\n",
    "pylab.show()\n",
    "\n",
    "print ('cell finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9eJXUeCh7sj"
   },
   "source": [
    "Just like before this will check the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3MZ-vE3Qh7sj"
   },
   "outputs": [],
   "source": [
    "# Cell 4.10\n",
    "\n",
    "results=conv_model.evaluate(\n",
    "    test_ds, steps=100)\n",
    "\n",
    "print(\"loss = {}\".format(results[0]))\n",
    "print(\"accuracy = {}\".format(results[1]))\n",
    "\n",
    "print ('cell finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "35VNik4Lh7sm"
   },
   "source": [
    "When working with images even a less than 1 percent difference can make a big difference in the utility of the classifier. Notice that the accuracy achieved with the convolutional model is significantly better than even the deep network from the last exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RO_0AZruh7sm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "04_mnist_cnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
